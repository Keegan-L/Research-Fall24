{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde03b78b62649b5a9c8b1eb182ed7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8193b23b816471b900ee80343ed262e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b16697fd55f491d8e6b5e9f79663777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7ad93bd85248ad8bdeb3fde677586c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfcdb18d27146a1a616363cad57fe15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/560 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a1e6981c1c468bbd0feeb8a99331ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-intermediate-step-955k-token-2T\")\n",
    "model = AutoModel.from_pretrained(\"TinyLlama/TinyLlama-1.1B-intermediate-step-955k-token-2T\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, sparsity_param: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.decoder = nn.Linear(hidden_size, input_size)\n",
    "        self.sparsity_param = sparsity_param\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.activation(self.encoder(x))\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "    \n",
    "    def get_sparsity_penalty(self, encoded):\n",
    "        avg_activation = torch.mean(encoded, dim=0)\n",
    "        kl_div = torch.sum(self.sparsity_param * torch.log(self.sparsity_param / avg_activation) + \n",
    "                          (1 - self.sparsity_param) * torch.log((1 - self.sparsity_param) / (1 - avg_activation)))\n",
    "        return kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_microparameters(text: str) -> Dict:\n",
    "    \"\"\"Extract statistical parameters from text.\"\"\"\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    sentences = re.split('[.!?]+', text)\n",
    "    words = text.split()\n",
    "    \n",
    "    return {\n",
    "        'n_paragraphs': len(paragraphs),\n",
    "        'n_sentences': len(sentences),\n",
    "        'n_words': len(words),\n",
    "        'avg_words_per_sentence': len(words) / len(sentences),\n",
    "        'avg_sentences_per_paragraph': len(sentences) / len(paragraphs),\n",
    "        'vocabulary_size': len(set(words)),\n",
    "        'word_frequency': Counter(words)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :].squeeze()\n",
    "        embeddings.append(embedding)\n",
    "    return torch.stack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_active_neurons(encoded_data: torch.Tensor) -> Dict:\n",
    "    \"\"\"Analyze which neurons are most active across texts.\"\"\"\n",
    "    activation_patterns = (encoded_data > 0).float()\n",
    "    neuron_activity = torch.sum(activation_patterns, dim=0)\n",
    "    \n",
    "    # Get top active neurons and their activation counts\n",
    "    top_neurons = torch.argsort(neuron_activity, descending=True)\n",
    "    \n",
    "    return {\n",
    "        'neuron_activity': neuron_activity,\n",
    "        'top_neurons': top_neurons,\n",
    "        'activation_patterns': activation_patterns\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: nan\n",
      "Epoch 20, Loss: nan\n",
      "Epoch 30, Loss: nan\n",
      "Epoch 40, Loss: nan\n",
      "Epoch 50, Loss: nan\n",
      "Epoch 60, Loss: nan\n",
      "Epoch 70, Loss: nan\n",
      "Epoch 80, Loss: nan\n",
      "Epoch 90, Loss: nan\n",
      "Epoch 100, Loss: nan\n",
      "\n",
      "Text 1 microparameters:\n",
      "n_paragraphs: 2245\n",
      "n_sentences: 6444\n",
      "n_words: 114126\n",
      "avg_words_per_sentence: 17.710428305400374\n",
      "avg_sentences_per_paragraph: 2.8703786191536746\n",
      "vocabulary_size: 13919\n",
      "\n",
      "Text 2 microparameters:\n",
      "n_paragraphs: 2130\n",
      "n_sentences: 9658\n",
      "n_words: 163818\n",
      "avg_words_per_sentence: 16.961896873058603\n",
      "avg_sentences_per_paragraph: 4.534272300469484\n",
      "vocabulary_size: 18826\n",
      "\n",
      "Text 3 microparameters:\n",
      "n_paragraphs: 341\n",
      "n_sentences: 1618\n",
      "n_words: 52978\n",
      "avg_words_per_sentence: 32.74289245982695\n",
      "avg_sentences_per_paragraph: 4.744868035190616\n",
      "vocabulary_size: 8472\n",
      "\n",
      "Text 4 microparameters:\n",
      "n_paragraphs: 1068\n",
      "n_sentences: 3441\n",
      "n_words: 29000\n",
      "avg_words_per_sentence: 8.427782621331009\n",
      "avg_sentences_per_paragraph: 3.2219101123595504\n",
      "vocabulary_size: 6954\n",
      "\n",
      "Text 5 microparameters:\n",
      "n_paragraphs: 2211\n",
      "n_sentences: 7724\n",
      "n_words: 130320\n",
      "avg_words_per_sentence: 16.8720870015536\n",
      "avg_sentences_per_paragraph: 3.493441881501583\n",
      "vocabulary_size: 14959\n",
      "\n",
      "Neuron activation analysis:\n",
      "Top 10 most active neurons: [86, 199, 150, 115, 151, 235, 164, 153, 154, 84]\n",
      "Activation counts: [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "# Load and process texts\n",
    "files = ['comedy.txt', 'fantasy.txt', 'power_strategy.txt', 'romance_tragedy.txt', 'romance.txt']\n",
    "texts = []\n",
    "for filename in files:\n",
    "    filepath = os.path.join('data', filename)\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        texts.append(f.read())\n",
    "\n",
    "# Extract microparameters\n",
    "micro_params = [extract_microparameters(text) for text in texts]\n",
    "\n",
    "# Get Gemma embeddings\n",
    "embeddings = get_embeddings(texts)\n",
    "\n",
    "# Initialize and train SAE\n",
    "input_size = embeddings.shape[1]  # Gemma's embedding dimension\n",
    "hidden_size = 256\n",
    "sae = SparseAutoencoder(input_size, hidden_size)\n",
    "optimizer = optim.Adam(sae.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    encoded, decoded = sae(embeddings)\n",
    "    reconstruction_loss = criterion(decoded, embeddings)\n",
    "    sparsity_loss = sae.get_sparsity_penalty(encoded)\n",
    "    loss = reconstruction_loss + 0.1 * sparsity_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Analyze results\n",
    "with torch.no_grad():\n",
    "    encoded_data, _ = sae(embeddings)\n",
    "    neuron_analysis = analyze_active_neurons(encoded_data)\n",
    "\n",
    "# Print microparameters\n",
    "for i, params in enumerate(micro_params):\n",
    "    print(f\"\\nText {i+1} microparameters:\")\n",
    "    for key, value in params.items():\n",
    "        if key != 'word_frequency':\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "# Print neuron activity\n",
    "print(\"\\nNeuron activation analysis:\")\n",
    "top_k = 10\n",
    "top_neurons = neuron_analysis['top_neurons'][:top_k]\n",
    "print(f\"Top {top_k} most active neurons:\", top_neurons.tolist())\n",
    "print(\"Activation counts:\", neuron_analysis['neuron_activity'][top_neurons].tolist())\n",
    "\n",
    "# Save results\n",
    "torch.save({\n",
    "    'sae_state': sae.state_dict(),\n",
    "    'embeddings': embeddings,\n",
    "    'encoded_data': encoded_data,\n",
    "    'micro_params': micro_params,\n",
    "    'neuron_analysis': neuron_analysis\n",
    "}, 'text_analysis_results.pt')\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(top_k), neuron_analysis['neuron_activity'][top_neurons].numpy())\n",
    "plt.title('Top Neuron Activations')\n",
    "plt.xlabel('Neuron Index')\n",
    "plt.ylabel('Activation Count')\n",
    "plt.savefig('neuron_activations.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
